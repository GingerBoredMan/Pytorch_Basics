{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.5,], [0.5,])\n",
    "                               ])\n",
    "\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2997, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "loss = criterion(logits,labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3050, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "logp = model(images)\n",
    "\n",
    "loss = criterion(logp,labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.3378e-04,  1.2234e+00],\n",
      "        [-2.4207e+00, -1.0050e+00]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.9520e-07, 1.4966e+00],\n",
      "        [5.8597e+00, 1.0100e+00]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7fbefea7cfd0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0916, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.1689e-04,  6.1168e-01],\n",
      "        [-1.2103e+00, -5.0249e-01]])\n",
      "tensor([[ 4.1689e-04,  6.1168e-01],\n",
      "        [-1.2103e+00, -5.0249e-01]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2) # dz/dx = x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "logp = model(images)\n",
    "loss = criterion(logp,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0049,  0.0049,  0.0049,  ...,  0.0049,  0.0049,  0.0049],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        ...,\n",
      "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0018,  0.0018,  0.0018],\n",
      "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [-0.0066, -0.0066, -0.0066,  ..., -0.0066, -0.0066, -0.0066]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model (Single step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer  = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (5): LogSoftmax()\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight -  Parameter containing:\n",
      "tensor([[ 0.0326,  0.0306,  0.0110,  ...,  0.0251,  0.0280,  0.0165],\n",
      "        [-0.0180, -0.0182,  0.0349,  ..., -0.0097,  0.0132,  0.0187],\n",
      "        [ 0.0074,  0.0195,  0.0029,  ..., -0.0287,  0.0084,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0076, -0.0221,  0.0206,  ..., -0.0068, -0.0196, -0.0296],\n",
      "        [-0.0059, -0.0027,  0.0212,  ..., -0.0048, -0.0328,  0.0080],\n",
      "        [ 0.0051, -0.0353, -0.0231,  ..., -0.0150,  0.0321,  0.0304]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [ 0.0027,  0.0027,  0.0027,  ...,  0.0027,  0.0027,  0.0027]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weight - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64,784)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = model.forward(images)\n",
    "loss = criterion(output,labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights Parameter containing:\n",
      "tensor([[ 0.0326,  0.0306,  0.0110,  ...,  0.0251,  0.0281,  0.0165],\n",
      "        [-0.0180, -0.0182,  0.0348,  ..., -0.0098,  0.0132,  0.0187],\n",
      "        [ 0.0074,  0.0195,  0.0029,  ..., -0.0287,  0.0083,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0075, -0.0221,  0.0206,  ..., -0.0068, -0.0196, -0.0296],\n",
      "        [-0.0059, -0.0027,  0.0211,  ..., -0.0048, -0.0328,  0.0080],\n",
      "        [ 0.0050, -0.0353, -0.0231,  ..., -0.0150,  0.0321,  0.0304]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.882084559148817\n",
      "Training loss: 0.8501697639539552\n",
      "Training loss: 0.5244155005732579\n",
      "Training loss: 0.42781076832875004\n",
      "Training loss: 0.3842552310622323\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images,labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1,784)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "ps = F.softmax(logits, dim=1)\n",
    "helper.view_classify(img.view(1,28,28),ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43104612827301025"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
