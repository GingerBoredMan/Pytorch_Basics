{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 233,
       "width": 233
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.682..  Test Loss: 0.993..  Test Accuracy: 0.635\n",
      "Epoch: 1/2..  Training Loss: 1.068..  Test Loss: 0.757..  Test Accuracy: 0.703\n",
      "Epoch: 1/2..  Training Loss: 0.853..  Test Loss: 0.683..  Test Accuracy: 0.721\n",
      "Epoch: 1/2..  Training Loss: 0.810..  Test Loss: 0.646..  Test Accuracy: 0.749\n",
      "Epoch: 1/2..  Training Loss: 0.738..  Test Loss: 0.623..  Test Accuracy: 0.757\n",
      "Epoch: 1/2..  Training Loss: 0.729..  Test Loss: 0.608..  Test Accuracy: 0.767\n",
      "Epoch: 1/2..  Training Loss: 0.664..  Test Loss: 0.581..  Test Accuracy: 0.789\n",
      "Epoch: 1/2..  Training Loss: 0.698..  Test Loss: 0.584..  Test Accuracy: 0.777\n",
      "Epoch: 1/2..  Training Loss: 0.638..  Test Loss: 0.565..  Test Accuracy: 0.792\n",
      "Epoch: 1/2..  Training Loss: 0.632..  Test Loss: 0.540..  Test Accuracy: 0.799\n",
      "Epoch: 1/2..  Training Loss: 0.648..  Test Loss: 0.554..  Test Accuracy: 0.797\n",
      "Epoch: 1/2..  Training Loss: 0.617..  Test Loss: 0.522..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.608..  Test Loss: 0.505..  Test Accuracy: 0.815\n",
      "Epoch: 1/2..  Training Loss: 0.612..  Test Loss: 0.518..  Test Accuracy: 0.806\n",
      "Epoch: 1/2..  Training Loss: 0.602..  Test Loss: 0.512..  Test Accuracy: 0.816\n",
      "Epoch: 1/2..  Training Loss: 0.606..  Test Loss: 0.489..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.587..  Test Loss: 0.492..  Test Accuracy: 0.823\n",
      "Epoch: 1/2..  Training Loss: 0.570..  Test Loss: 0.490..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.597..  Test Loss: 0.527..  Test Accuracy: 0.801\n",
      "Epoch: 1/2..  Training Loss: 0.621..  Test Loss: 0.512..  Test Accuracy: 0.810\n",
      "Epoch: 1/2..  Training Loss: 0.581..  Test Loss: 0.493..  Test Accuracy: 0.826\n",
      "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.482..  Test Accuracy: 0.823\n",
      "Epoch: 1/2..  Training Loss: 0.547..  Test Loss: 0.475..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.561..  Test Loss: 0.470..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.553..  Test Loss: 0.482..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.489..  Test Loss: 0.466..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.545..  Test Loss: 0.482..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.462..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.472..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.544..  Test Loss: 0.460..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.561..  Test Loss: 0.462..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.518..  Test Loss: 0.475..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.528..  Test Loss: 0.486..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.510..  Test Loss: 0.461..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.473..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.532..  Test Loss: 0.454..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.490..  Test Loss: 0.455..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.505..  Test Loss: 0.451..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.500..  Test Loss: 0.462..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.512..  Test Loss: 0.451..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.457..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 0.528..  Test Loss: 0.442..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.515..  Test Loss: 0.435..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.447..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.516..  Test Loss: 0.450..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.495..  Test Loss: 0.428..  Test Accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cc11e1013989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
     ]
    }
   ],
   "source": [
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
